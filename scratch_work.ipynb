{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chess Testing",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgDha-xBOVwB",
        "colab_type": "code",
        "outputId": "1b433a56-1f55-44ca-ea49-2b4788d3eb12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install -q tensorflow==2.0.0-beta1\n",
        "!pip install python-chess"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 87.9MB 482kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.1MB 27.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 43.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-chess in /usr/local/lib/python3.6/dist-packages (0.23.11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJDpqALgR5C7",
        "colab_type": "code",
        "outputId": "edf4312c-bc1e-40d5-9a87-14a33d2f43a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import chess\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Input, Lambda\n",
        "from keras import backend as K\n",
        "from tensorflow import keras"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm7R6H27OlVy",
        "colab_type": "code",
        "outputId": "71fc64d9-7569-46cc-d4e9-4fb364c1592e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "mat = np.random.randint(0, 100, (3, 6, 5))\n",
        "mat"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[65, 74, 24, 49, 48],\n",
              "        [40, 53, 35, 79, 72],\n",
              "        [88, 19, 59, 62,  9],\n",
              "        [72, 35, 42, 66,  8],\n",
              "        [95, 33, 15, 10, 92],\n",
              "        [53, 79, 45, 23, 59]],\n",
              "\n",
              "       [[53, 55, 47, 13, 46],\n",
              "        [ 4, 94, 97, 34, 25],\n",
              "        [ 7, 63, 92, 83, 78],\n",
              "        [22, 11, 25, 59, 73],\n",
              "        [24, 12, 30, 41, 56],\n",
              "        [54, 73, 26, 35, 24]],\n",
              "\n",
              "       [[71, 76, 53, 46, 92],\n",
              "        [28, 70, 84, 59, 56],\n",
              "        [89, 60, 30, 91, 94],\n",
              "        [36, 22, 38, 85, 20],\n",
              "        [37, 14, 98,  5, 26],\n",
              "        [75, 57, 91, 48, 96]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZYmQ-IgO29e",
        "colab_type": "code",
        "outputId": "66623b98-4268-470e-b760-b111bd526680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "board = chess.Board()\n",
        "board.legal_moves"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<LegalMoveGenerator at 0x7f1c13d1fda0 (Nh3, Nf3, Nc3, Na3, h3, g3, f3, e3, d3, c3, b3, a3, h4, g4, f4, e4, d4, c4, b4, a4)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRhEQ_I3TXhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_mat(piece, color):\n",
        "  squareSet = board.pieces(piece, color)\n",
        "  return get_bin_mat(squareSet);\n",
        "\n",
        "def get_bin_mat(squareSet):\n",
        "  mat = np.zeros((8,8))\n",
        "  for x in range(0, 8):\n",
        "    for y in range(0, 8):\n",
        "        if(y*8 + x in squareSet):\n",
        "          # The 7 - is used to flip the board representation\n",
        "          mat[7 - y, x] = 1\n",
        "            \n",
        "  return mat\n",
        "\n",
        "\n",
        "def get_dual_bin_mat(piece):\n",
        "  whiteSquareSet = board.pieces(piece, chess.WHITE)\n",
        "  blackSquareSet = board.pieces(piece, chess.BLACK)\n",
        "  mat = np.zeros((8,8))\n",
        "  for x in range(0, 8):\n",
        "    for y in range(0, 8):\n",
        "        if(y*8 + x in whiteSquareSet):\n",
        "          # The 7 - is used to flip the board representation\n",
        "          mat[7 - y, x] = 1\n",
        "        elif(y*8 + x in blackSquareSet):\n",
        "          mat[7 - y, x] = -1\n",
        "            \n",
        "  return mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ7P_PFH8WdK",
        "colab_type": "text"
      },
      "source": [
        "Input data:\n",
        "\n",
        "  (6 pieces + 1 for meta state ) * 2 players\n",
        "  \n",
        "  8 rows\n",
        "  \n",
        "  8 columns\n",
        "  \n",
        " => 8 * 8 * 12 = 768\n",
        " \n",
        " \n",
        " Output data:\n",
        " \n",
        " - Assume predicting five moves\n",
        " - initial location, and new location\n",
        " \n",
        " \n",
        "Array of objects/tuples\n",
        "[{initial location, new location},...]\n",
        " \n",
        " \n",
        " => 5 * 2 * 64 = 640\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhLuexsTIrwg",
        "colab_type": "code",
        "outputId": "e1d2b6de-9a4b-48f2-a9be-763265a7a923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "mat = get_dual_bin_mat(chess.PAWN)\n",
        "mat.shape\n",
        "\n",
        "test = np.array([get_mat(i, chess.WHITE) for i in range(1,7)] + [get_mat(i, chess.BLACK) for i in range(1,7)])\n",
        "test.shape\n",
        "\n",
        "y = test.reshape((-1, 12, 8, 8))\n",
        "y.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 12, 8, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IaUF3KYeNY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create model\n",
        "model = Sequential()\n",
        "#add model layers\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(12,8,8)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='linear'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxatCV9I8unU",
        "colab_type": "code",
        "outputId": "bca4d563-114f-45c0-c3f9-1db2ddf39e06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x = model.predict(y)\n",
        "x"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.04705101, -0.02663097, -0.04413891,  0.01072281,  0.04222774,\n",
              "         0.01144807, -0.01855633, -0.02139407, -0.03520958,  0.04532561]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL9RnEF02w2h",
        "colab_type": "code",
        "outputId": "a2bf5588-ea26-4d73-d733-11a19026db9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 10, 6, 64)         4672      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 8, 4, 32)          18464     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                10250     \n",
            "=================================================================\n",
            "Total params: 33,386\n",
            "Trainable params: 33,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh4Q_A627s3r",
        "colab_type": "code",
        "outputId": "d3060d1a-f776-4184-f747-1abd1acc5a12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "NUM_OUTPUTS = 5\n",
        "\n",
        "\n",
        "#inp is a \"tensor\", that can be passed when calling other layers to produce an output \n",
        "inp = Input((12,8,8)) #supposing you have ten numeric values as input \n",
        "\n",
        "\n",
        "#here, SomeLayer() is defining a layer, \n",
        "#and calling it with (inp) produces the output tensor x\n",
        "# x = SomeLayer(blablabla)(inp) \n",
        "# x = SomeOtherLayer(blablabla)(x) #here, I just replace x, because this intermediate output is not interesting to keep\n",
        "\n",
        "x = Conv2D(64, kernel_size=3, activation='relu', input_shape=(12,8,8))(inp)\n",
        "\n",
        "x = Conv2D(32, kernel_size=3, activation='relu', input_shape=(12,8,8))(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "\n",
        "outputs = []\n",
        "\n",
        "for n in range(NUM_OUTPUTS):\n",
        "  outputs.append(Dense(128, activation='softmax')(x))\n",
        "\n",
        "\n",
        "#here, I want to keep the two different outputs for defining the model\n",
        "#notice that both left and right are called with the same input x, creating a fork\n",
        "# out1 = LeftSideLastLayer(balbalba)(x)    \n",
        "# out2 = RightSideLastLayer(banblabala)(x)\n",
        "\n",
        "\n",
        "#here, you define which path you will follow in the graph you've drawn with layers\n",
        "#notice the two outputs passed in a list, telling the model I want it to have two outputs.\n",
        "model = Model(inp, outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) #loss can be one for both sides or a list with different loss functions for out1 and out2    \n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 12, 8, 8)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 10, 6, 64)    4672        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 8, 4, 32)     18464       conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 1024)         0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 128)          131200      flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 128)          131200      flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 128)          131200      flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 128)          131200      flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 128)          131200      flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 679,136\n",
            "Trainable params: 679,136\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xyl3iUZBFybO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = model.predict(y)\n",
        "# np.argmax(p[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiHZYClMOebr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def interpret_pred(p):\n",
        "  num_outputs = len(p)\n",
        "  \n",
        "  moves = []\n",
        "  for out in p:\n",
        "    # There's an extra list wrapping for some reason\n",
        "    out = out[0]\n",
        "    start = np.argmax(out[:64])\n",
        "    end = np.argmax(out[64:])\n",
        "    \n",
        "    #print(chess.SQUARE_NAMES[start])\n",
        "#     print(end)\n",
        "    \n",
        "    moves.append((chess.SQUARE_NAMES[start],\n",
        "                  chess.SQUARE_NAMES[end]))\n",
        "    \n",
        "  return moves"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KyQwbqmYbx0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d637721d-4429-46ed-b010-2b0d6647f737"
      },
      "source": [
        "moves = interpret_pred(p)\n",
        "print(moves)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('f1', 'b4'), ('b4', 'a5'), ('f4', 'g3'), ('h6', 'd7'), ('g4', 'c5')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clSTqUeBdIEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fe71315b-d6fa-426d-e72f-ab278a653994"
      },
      "source": [
        "p"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0.00764698, 0.00706254, 0.00771121, 0.00779736, 0.00793065,\n",
              "         0.00873157, 0.00770415, 0.00780445, 0.0075901 , 0.00765776,\n",
              "         0.00835187, 0.00739352, 0.00766488, 0.00761447, 0.00710705,\n",
              "         0.00758018, 0.00755843, 0.00779666, 0.00755307, 0.00769361,\n",
              "         0.00822804, 0.00709443, 0.00801772, 0.00816545, 0.00871106,\n",
              "         0.00732566, 0.00795426, 0.00860787, 0.00828659, 0.00798255,\n",
              "         0.00854007, 0.00810956, 0.00793171, 0.00761743, 0.00775256,\n",
              "         0.00785392, 0.00804098, 0.00725975, 0.00787752, 0.00778343,\n",
              "         0.00724136, 0.00689761, 0.00785535, 0.00748082, 0.00816488,\n",
              "         0.00748195, 0.00778243, 0.00826092, 0.00753153, 0.00799314,\n",
              "         0.00841984, 0.00808385, 0.0083874 , 0.00839574, 0.00805726,\n",
              "         0.00759641, 0.00766094, 0.00800855, 0.00788796, 0.00834842,\n",
              "         0.00729032, 0.00727751, 0.00831852, 0.00757592, 0.00795694,\n",
              "         0.00733263, 0.00724402, 0.00805666, 0.00726766, 0.00721852,\n",
              "         0.00798206, 0.00856476, 0.00857823, 0.00755098, 0.00727746,\n",
              "         0.00723129, 0.00774509, 0.00685464, 0.007368  , 0.00733584,\n",
              "         0.00801378, 0.00770797, 0.00805736, 0.00839227, 0.00768378,\n",
              "         0.00746761, 0.00781401, 0.00851036, 0.00802379, 0.00881665,\n",
              "         0.00659282, 0.00748738, 0.00774386, 0.00713646, 0.00786669,\n",
              "         0.0075724 , 0.00797712, 0.00776164, 0.00856575, 0.00779661,\n",
              "         0.00747356, 0.00786144, 0.00775456, 0.00802415, 0.00773346,\n",
              "         0.00798804, 0.00751656, 0.00755509, 0.00787675, 0.00834846,\n",
              "         0.00839979, 0.00735262, 0.0080102 , 0.00774269, 0.00810993,\n",
              "         0.00821238, 0.00792532, 0.00738247, 0.00766367, 0.00793633,\n",
              "         0.00761444, 0.00797083, 0.0080672 , 0.00796466, 0.0076663 ,\n",
              "         0.00742809, 0.00826952, 0.00850871]], dtype=float32),\n",
              " array([[0.00735573, 0.00798096, 0.00804147, 0.00831358, 0.00781236,\n",
              "         0.00830884, 0.00733654, 0.0078133 , 0.00774876, 0.00767167,\n",
              "         0.00788597, 0.00732291, 0.00781339, 0.00729638, 0.0077906 ,\n",
              "         0.00822617, 0.00744883, 0.0078037 , 0.00838341, 0.00760049,\n",
              "         0.00843498, 0.00769704, 0.00721545, 0.00715457, 0.00851394,\n",
              "         0.00900394, 0.00807879, 0.00723306, 0.00733453, 0.0085108 ,\n",
              "         0.00751783, 0.00792764, 0.007298  , 0.00808977, 0.00796892,\n",
              "         0.00788918, 0.00798082, 0.0078874 , 0.00756806, 0.00864749,\n",
              "         0.0083674 , 0.00785354, 0.00801954, 0.0084543 , 0.00711001,\n",
              "         0.00792231, 0.00748647, 0.00741657, 0.00744751, 0.00806915,\n",
              "         0.00770962, 0.00798729, 0.00849123, 0.00730303, 0.00723405,\n",
              "         0.00797041, 0.00767052, 0.00786602, 0.00829259, 0.00859506,\n",
              "         0.00734676, 0.00801574, 0.00780751, 0.00744097, 0.00843743,\n",
              "         0.00730785, 0.00752048, 0.00816296, 0.00718295, 0.0081541 ,\n",
              "         0.00801713, 0.00779596, 0.00746695, 0.00766379, 0.00717262,\n",
              "         0.00787544, 0.0077179 , 0.00767918, 0.00810908, 0.00800431,\n",
              "         0.00759324, 0.0072951 , 0.00751044, 0.00775009, 0.00794628,\n",
              "         0.00800071, 0.00833859, 0.00676419, 0.00724086, 0.00798083,\n",
              "         0.0072881 , 0.00823685, 0.00768073, 0.00764216, 0.00822661,\n",
              "         0.00785101, 0.00860199, 0.00853581, 0.00786202, 0.00738292,\n",
              "         0.0072229 , 0.00855161, 0.00809711, 0.00765401, 0.00850586,\n",
              "         0.00797307, 0.00810022, 0.00808372, 0.00674473, 0.0081166 ,\n",
              "         0.00742443, 0.00788151, 0.0074126 , 0.00749476, 0.00749832,\n",
              "         0.00734   , 0.00841721, 0.00769977, 0.00755252, 0.00820146,\n",
              "         0.0078441 , 0.0079759 , 0.00760492, 0.00808711, 0.00810531,\n",
              "         0.00779388, 0.00691658, 0.0079182 ]], dtype=float32),\n",
              " array([[0.00754198, 0.00698427, 0.00816416, 0.00825391, 0.00781071,\n",
              "         0.00811701, 0.00811882, 0.00777723, 0.00808717, 0.00734361,\n",
              "         0.00772899, 0.00777576, 0.00726848, 0.00742053, 0.00774577,\n",
              "         0.00795803, 0.00833164, 0.00789192, 0.00817304, 0.00702921,\n",
              "         0.00713616, 0.00786085, 0.00793339, 0.00764518, 0.00767855,\n",
              "         0.00799075, 0.00738772, 0.00759793, 0.00753081, 0.00853107,\n",
              "         0.00832156, 0.00839688, 0.00789356, 0.00762647, 0.00666695,\n",
              "         0.00835444, 0.00803651, 0.00775916, 0.00834029, 0.00831016,\n",
              "         0.00767575, 0.00765294, 0.00748565, 0.00816596, 0.00781762,\n",
              "         0.00789769, 0.00757148, 0.00758602, 0.00765797, 0.00755848,\n",
              "         0.00726206, 0.00762285, 0.0070265 , 0.00751951, 0.00848255,\n",
              "         0.00753108, 0.0083013 , 0.0069738 , 0.0078792 , 0.008514  ,\n",
              "         0.00813593, 0.00813339, 0.00722855, 0.00820823, 0.0077083 ,\n",
              "         0.00813769, 0.0079961 , 0.00798829, 0.00766432, 0.00750272,\n",
              "         0.0076379 , 0.00813656, 0.00736349, 0.0081496 , 0.00814365,\n",
              "         0.00801046, 0.00771302, 0.00685624, 0.00735574, 0.00742344,\n",
              "         0.00819085, 0.00814898, 0.00859637, 0.00764494, 0.00835287,\n",
              "         0.00826714, 0.00877922, 0.00786793, 0.00761585, 0.00829558,\n",
              "         0.00786493, 0.00724144, 0.0078192 , 0.00748841, 0.00736998,\n",
              "         0.00769756, 0.0075656 , 0.00832028, 0.00771386, 0.00739461,\n",
              "         0.00762246, 0.00773654, 0.0074305 , 0.00778233, 0.00755853,\n",
              "         0.00756912, 0.00718264, 0.00760804, 0.0085052 , 0.00767838,\n",
              "         0.00847113, 0.00767106, 0.00780999, 0.00722501, 0.00805099,\n",
              "         0.00835842, 0.00741281, 0.00800707, 0.00788597, 0.00810856,\n",
              "         0.00773749, 0.00819947, 0.00767238, 0.00841199, 0.00823225,\n",
              "         0.00765182, 0.00794412, 0.00804359]], dtype=float32),\n",
              " array([[0.00837614, 0.0082209 , 0.00828467, 0.00705331, 0.00726802,\n",
              "         0.00745898, 0.00755647, 0.00833296, 0.00773384, 0.00832377,\n",
              "         0.00834812, 0.00721988, 0.00807259, 0.00796811, 0.00813456,\n",
              "         0.00747351, 0.00805568, 0.00770937, 0.00794469, 0.00777916,\n",
              "         0.00791556, 0.00751515, 0.00706366, 0.00825967, 0.00787616,\n",
              "         0.00753637, 0.00726174, 0.00755364, 0.00744975, 0.00770971,\n",
              "         0.00774723, 0.00777634, 0.00773798, 0.00834998, 0.00740651,\n",
              "         0.00735331, 0.00803237, 0.00734719, 0.00764666, 0.00746831,\n",
              "         0.00765691, 0.00785946, 0.00800903, 0.00730298, 0.00734377,\n",
              "         0.00813657, 0.00795614, 0.00853652, 0.00843078, 0.00844356,\n",
              "         0.00756012, 0.0075589 , 0.00693621, 0.0073942 , 0.00815955,\n",
              "         0.0082645 , 0.00740553, 0.00763759, 0.00736448, 0.00767527,\n",
              "         0.00782543, 0.00780583, 0.00805633, 0.00789605, 0.00764602,\n",
              "         0.00730939, 0.00827409, 0.00707932, 0.00797522, 0.00788256,\n",
              "         0.00862174, 0.0073918 , 0.00801397, 0.00796434, 0.00794904,\n",
              "         0.00836216, 0.00779449, 0.00775803, 0.00738354, 0.00769236,\n",
              "         0.00800392, 0.00674736, 0.00781732, 0.00719381, 0.00811649,\n",
              "         0.00764479, 0.00764445, 0.00781695, 0.00733072, 0.00845006,\n",
              "         0.00732672, 0.00782559, 0.00788247, 0.00764848, 0.00760185,\n",
              "         0.00785402, 0.00810535, 0.00804593, 0.00711796, 0.00747112,\n",
              "         0.00756999, 0.00791017, 0.00867575, 0.00833861, 0.00755011,\n",
              "         0.00807015, 0.00715623, 0.00808969, 0.00704128, 0.00727286,\n",
              "         0.00813813, 0.00764567, 0.00875069, 0.0077915 , 0.00812544,\n",
              "         0.00925262, 0.00828555, 0.00761746, 0.00870817, 0.00840018,\n",
              "         0.0078102 , 0.00751719, 0.00825495, 0.00793998, 0.00763819,\n",
              "         0.00814441, 0.00807587, 0.00794775]], dtype=float32),\n",
              " array([[0.00751163, 0.00713312, 0.00767096, 0.00838246, 0.00811074,\n",
              "         0.00795628, 0.00783589, 0.00756621, 0.00751787, 0.00777688,\n",
              "         0.00721914, 0.00740571, 0.00811564, 0.00760261, 0.00710844,\n",
              "         0.0079717 , 0.00811944, 0.00733716, 0.00830652, 0.00829367,\n",
              "         0.00776791, 0.00783822, 0.00780443, 0.00798711, 0.0074672 ,\n",
              "         0.00779294, 0.00763189, 0.00798535, 0.00780476, 0.00747905,\n",
              "         0.00866656, 0.00793032, 0.00763467, 0.00790667, 0.00861649,\n",
              "         0.00748615, 0.00753977, 0.00800192, 0.00804912, 0.00731238,\n",
              "         0.00747763, 0.00745859, 0.00793029, 0.00827798, 0.00794545,\n",
              "         0.00819235, 0.00788434, 0.00787951, 0.00822973, 0.00798373,\n",
              "         0.0080656 , 0.00849744, 0.00784575, 0.00758209, 0.00734564,\n",
              "         0.0085352 , 0.00782431, 0.00692147, 0.00751851, 0.00845449,\n",
              "         0.00801696, 0.00752525, 0.00741083, 0.00771045, 0.00772098,\n",
              "         0.00838662, 0.00783726, 0.00794805, 0.00787455, 0.00801312,\n",
              "         0.00778109, 0.00806578, 0.00819134, 0.00747287, 0.00773715,\n",
              "         0.00812618, 0.00737169, 0.00788553, 0.00789446, 0.00725431,\n",
              "         0.00790966, 0.00822101, 0.00763437, 0.00756546, 0.00806808,\n",
              "         0.00720028, 0.00856531, 0.00836298, 0.00743053, 0.00787121,\n",
              "         0.00771273, 0.00743274, 0.00720582, 0.00787116, 0.00833578,\n",
              "         0.00764201, 0.00802313, 0.00797631, 0.00871323, 0.00758045,\n",
              "         0.00772832, 0.00762721, 0.00748438, 0.0080963 , 0.00815952,\n",
              "         0.00764411, 0.00773267, 0.00824295, 0.00746579, 0.00849076,\n",
              "         0.00752048, 0.00790582, 0.0085638 , 0.00796444, 0.00774734,\n",
              "         0.00763524, 0.00684787, 0.00794452, 0.00739255, 0.00738002,\n",
              "         0.00718829, 0.00790911, 0.00788126, 0.00749995, 0.00725352,\n",
              "         0.00812932, 0.00789866, 0.007624  ]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FITnn_s-UzTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}